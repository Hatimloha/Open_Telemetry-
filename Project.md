# Otel Astronomy Shop Demo App

## Prerequisites:
- AWS Cloud
### Steps:
Create EC2 instance with the following configurations:
- Ubuntu 22
- T2.xlarge (More than 6GB ram required)
- 15GB storage


```shell
git clone https://github.com/open-telemetry/opentelemetry-demo.git
cd opentelemetry-demo/
```

> As a DevOps Engineer you should understand what this project is doing and how things are happening so let’s understand the docker compose file responsible for deploying the app.

## Understanding the docker compose file structure!

> This Docker Compose file is designed to set up an observability demo environment using various microservices. If you're new to observability, here's how you can understand this setup:
https://github.com/open-telemetry/opentelemetry-demo/blob/main/docker-compose.yml

## Breakdown of the File:
- **Logging Configuration (`x-default-logging`)**:
    - This section defines how logs are handled. The logs are stored in JSON format with limits on file size (`5m`) and number of files (`2`). The `tag` option adds a name tag to each log entry, which is useful for identifying which service generated the log.
- **Networks**:
    - The `networks` section defines a custom network called `opentelemetry-demo` using the bridge driver, which allows containers to communicate with each other.
- **Services**:
    - Each service represents a different microservice in the application. These microservices work together to form a complete application.

## Service Details:
> Microservices in the app and the languages they are written in.
- Core Demo Services: Application services written in different languages.
- Dependent Services: Services that the application services depend on like Redis, Kafka etc.
- Telemetry Components: Components that deal with the telemetry data generated by the above services like Collector, Prometheus, Grafana, OpenSearch, Jaeger.


- **Accounting Service (`accountingservice`)**:
    - **Image**: Specifies the Docker image used to run the service.
    - **Build**: Defines how the service is built, including the Dockerfile to use.
    - **Environment Variables**: Configures how the service interacts with other parts of the system, like setting the endpoint for sending telemetry data to an OpenTelemetry collector (`OTEL_EXPORTER_OTLP_ENDPOINT`).
    - **Dependencies**: `depends_on` ensures certain services like `otelcol` (OpenTelemetry Collector) and `kafka` are started before this service.
    - **Logging**: Uses the predefined logging configuration.
- **Ad Service (`adservice`)**:
    - Similar to the accounting service but with additional ports exposed and configured for sending logs and metrics to the observability system.
- **Cart Service (`cartservice`)**:
    - Handles shopping cart operations and interacts with other services like `checkoutservice`, all while sending telemetry data to OpenTelemetry.
- **Checkout Service (`checkoutservice`)**:
    - Manages the checkout process. It depends on multiple other services to ensure the whole checkout flow works properly. It also sends data for observability.
- **Other Services (e.g., `currencyservice`, `emailservice`, `frauddetectionservice`)**:
    - Each of these services plays a specific role in the application (like handling currency conversion, sending emails, or detecting fraud) and is configured similarly with dependencies, logging, and observability settings.
- **Frontend (`frontend`) and Frontend Proxy (`frontendproxy`)**:
    - The `frontend` service is the user-facing part of the application, while `frontendproxy` helps manage traffic between the frontend and backend services.
- **Image Provider (`imageprovider`) and Load Generator (`loadgenerator`)**:
    - The `imageprovider` supplies images to the frontend, and the `loadgenerator` simulates user traffic to test the system'ssrc/flagd/demo.flagd.json performance.

## Observability in Action:
- **Telemetry Data**: Most services are configured to send data (logs, metrics, and traces) to an OpenTelemetry Collector (`otelcol`), which collects and processes this data, making it available for analysis.
- **Dependencies**: The `depends_on` condition ensures that services are started in the right order, crucial for a distributed system to function properly.
> We can also check how the OTEL variables are being passed as environment variables for the core demo and dependent services. The config files and the code for all these are in the `/src` folder. You can go ahead and look at how each service is instrumented considering the language and [this](https://opentelemetry.io/docs/demo/) documentation here helps us to better understand the instrumentation for each service in detail.

## Otel Collector
**Receivers:** Collect telemetry data (traces, metrics, logs) from various sources (e.g., applications, services, or endpoints).

**Exporters:** Send the collected telemetry data to external systems or storage (e.g., logging systems, metrics platforms).

**Processors:** Transform or modify the telemetry data between collection and export (e.g., batch processing, filtering, or data enrichment).

**Connectors (spanmetrics):** Extracts metrics from trace data (span metrics) for further processing or export.

**Service:** Defines how telemetry data flows through the system, specifying which receivers, processors, and exporters are used for traces, metrics, and logs.

```shell
# Copyright The OpenTelemetry Authors
# SPDX-License-Identifier: Apache-2.0

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: ${env:OTEL_COLLECTOR_HOST}:${env:OTEL_COLLECTOR_PORT_GRPC}
      http:
        endpoint: ${env:OTEL_COLLECTOR_HOST}:${env:OTEL_COLLECTOR_PORT_HTTP}
        cors:
          allowed_origins:
            - "http://*"
            - "https://*"
  httpcheck/frontendproxy:
    targets:
      - endpoint: http://frontendproxy:${env:ENVOY_PORT}
  docker_stats:
    endpoint: unix:///var/run/docker.sock
  redis:
    endpoint: "valkey-cart:6379"
    username: "valkey"
    collection_interval: 10s
  # Host metrics
  hostmetrics:
    root_path: /hostfs
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      disk:
      load:
      filesystem:
        exclude_mount_points:
          mount_points:
            - /dev/*
            - /proc/*
            - /sys/*
            - /run/k3s/containerd/*
            - /var/lib/docker/*
            - /var/lib/kubelet/*
            - /snap/*
          match_type: regexp
        exclude_fs_types:
          fs_types:
            - autofs
            - binfmt_misc
            - bpf
            - cgroup2
            - configfs
            - debugfs
            - devpts
            - devtmpfs
            - fusectl
            - hugetlbfs
            - iso9660
            - mqueue
            - nsfs
            - overlay
            - proc
            - procfs
            - pstore
            - rpc_pipefs
            - securityfs
            - selinuxfs
            - squashfs
            - sysfs
            - tracefs
          match_type: strict
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      network:
      paging:
      processes:
      process:
        mute_process_exe_error: true
        mute_process_io_error: true
        mute_process_user_error: true
  # Collector metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otelcol'
          scrape_interval: 10s
          static_configs:
            - targets: ['0.0.0.0:8888']

exporters:
  debug:
  otlp:
    endpoint: "jaeger:4317"
    tls:
      insecure: true
  otlphttp/prometheus:
    endpoint: "http://prometheus:9090/api/v1/otlp"
    tls:
      insecure: true
  opensearch:
    logs_index: otel
    http:
      endpoint: "http://opensearch:9200"
      tls:
        insecure: true

processors:
  batch:
  transform:
    error_mode: ignore
    trace_statements:
      - context: span
        statements:
          # could be removed when https://github.com/vercel/next.js/pull/64852 is fixed upstream
          - replace_pattern(name, "\\?.*", "")
          - replace_match(name, "GET /api/products/*", "GET /api/products/{productId}")

connectors:
  spanmetrics:

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [transform, batch]
      exporters: [otlp, debug, spanmetrics]
    metrics:
      receivers: [hostmetrics, docker_stats, httpcheck/frontendproxy, otlp, prometheus, redis, spanmetrics]
      processors: [batch]
      exporters: [otlphttp/prometheus, debug]
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [opensearch, debug]
```
